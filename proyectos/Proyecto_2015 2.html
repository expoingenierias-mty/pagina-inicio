<!DOCTYPE html>
<html lang="pl">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Muestra Virtual</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" />
    <link rel="stylesheet" href="../assets/css/projects.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@200&display=swap" rel="stylesheet" />
    <link href="<link href=&quot;https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap&quot; rel=&quot;stylesheet&quot;>" />
    <link rel="icon" href="assets/img/Screen Shot 2022-04-03 at 17.10.51.png" />
  </head>
  <body style="background-image:url(../fotos_proyectos/Proyecto_2015/abstract-texture-hd-4k-wallpaper-preview.jpg)">
    <div class="container-fluid px-5 pb-5">
      <div class="row pt-2">
        <div class="col-lg-10">
          <h4>
            INVESTIGACION Y DESARROLLO DE PROPUESTAS DE MEJORA
          </h4>
          <h1>
            Extended Dense Video Captions Using Input Clipping in a Bi-modal Transformer
          </h1>
        </div>
        <div class="col-lg-2 text-center">
          <img src="../fotos_proyectos/Proyecto_2015/" width="100px" onerror="this.style.display='none'" />
        </div>
      </div>
      <div class="row pt-3">
        <div class="col-lg-12">
          <p>
            The ability of educators to adapt classroom activities in response to student behavior during class is constrained to human limitations, especially when the student-to-professor ratio is high. \textit{Smart classrooms} use monitoring devices that generate visual and audio data which can be analyzed by deep learning models, surpassing such human limitations. Dense Video Captioning, the task of localizing and describing multiple events in videos, is applicable in this context. One of the state-of-the-art models, the Bi-modal Transformer, can be implemented with input clipping to extend the amount of events it describes. With preliminary results, we achieve an increase of the amount of descriptions generated in each of the samples.
          </p>
        </div>
      </div>
      <div class="row pt-2" id="images">
        <div class="col-lg-4  my-auto text-center ">
          <img class="project-img" src="../fotos_proyectos/Proyecto_2015/Model.png" />
        </div>
        <div class="col-lg-4  my-auto text-center ">
          <img class="project-img" src="../fotos_proyectos/Proyecto_2015/pull_figure.png" />
        </div>
        <div class="col-lg-4  my-auto text-center">
          <img class="project-img" src="../fotos_proyectos/Proyecto_2015/imagen.JPG" />
        </div>
      </div>
      <div class="row pt-3 text-center" id="video">
        <div class="col-lg-12">
          <a class="btn btn-primary" href="https://drive.google.com/open?id=13XIOPrtFYvU7ubos9BsiBNhOPKxFOdCi">
            Ver Video
          </a>
        </div>
      </div>
      <div class="row pt-3" id="contact-info">
        <div class="col-md-12">
          <h4>
            Contacto
          </h4>
          <p>
            Oscar Miranda Escalante
A01630791@tec.mx
+52 1 33 3465 9159

Leyre Carpinteyro Palos
A01610296@tec.mx
+52 44 4143 0013
          </p>
        </div>
      </div>
    </div>
  </body>
</html>